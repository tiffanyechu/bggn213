---
title: "Class10 Machine Learning Project"
author: "Tiffany Chu"
date: "February 7, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Get our input data

Our data for today comes from Madison, Wisconsin biopsies of breast tissue: the Wisconsin Breast Cancer Diagnostic Data Set

```{r}
wisc.df <- read.csv("WisconsinCancer.csv")
head(wisc.df)
```

```{r}
wisc.data <- as.matrix(wisc.df[,3:32])
head(wisc.data)
```

Question. How many patients are there in this dataset?
```{r}
nrow(wisc.data)
```

Question. How many cancer and non-cancer patients are there?
Answer. Column 2 has diagnosis, M for malignant and B for benign.
```{r}
table(wisc.df$diagnosis)
```
alternatively
```{r}
sum(wisc.df$diagnosis == "M")
```

Question. How many of these columns give mean data?

```{r}
colnames(wisc.df)

```
Answer. `grep()` looks for pattern within vector.
```{r}
grep("_mean", colnames(wisc.df))
```
`grep` returns location of match.
```{r}
grep("_mean", colnames(wisc.df), value = TRUE)
```

Use `length()` to out how many matches - do not use `sum()` because sum will add up column location numbers.
```{r}
length( grep("_mean", colnames(wisc.df)) )
```

## Enter Principle Component Analysis

First we need to check whether our input data should be scaled.
a) Look at mean values and standard deviation in each column - if they are not similar, we will need to scale.
b) Use `sd()` and `mean()` to check all columns in `wisc.data` because `wisc.data` has been cleaned up and had irrelevant columns removed

```{r}
round( apply(wisc.data, 2, sd), 2)
```
Yes, data needs scaling.
```{r}
#Perform PCA on wisc.data 
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```

Data is complex, so biplot does not return a useful description (very messy).
```{r}
biplot(wisc.pr)
```

Let's make our own PCA plot.  To do this, we need to figure out what is returned, so we will use `attributes()` to access the results within the `wisc.pr` object.
```{r}
attributes(wisc.pr)
```
Therefore, $x is where our data lives, where our principal components are stored as **columns** PC1, PC2, ...

We want $x component to make our PCA plot! Let's plot PC1:PC2

```{r}
plot(wisc.pr$x[ ,1:2])
```

Let's color the points by diagnosis
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=wisc.df$diagnosis)
```

Each point summarizes a patient, and PCA compresses data down to a lower dimension by focusing on the differences 

## Section 3: Hierarchical clustering

Can we find a separation of cancer from non-cancer using a clustering method on the original input data?

Use the `hclust()` function on the `wisc.data` object that we used for PCA.

```{r}
hc <- hclust( dist(wisc.data) )
plot(hc)
```

This tree isn't very helpful since we can't tell where is a good place to *cut* the tree.

We can cluster in PC space - that is, use the results of PCA to do the clustering:

```{r}
wisc.pr.hc <- hclust( dist(wisc.pr$x[,1:3]), method="ward.D2")
plot(wisc.pr.hc)
```

```{r}
grps <- cutree(wisc.pr.hc, k=2)
table(grps)
```
```{r}
table(grps, wisc.df$diagnosis)
```

This tells us that in cluster 1, 24 members are benign and 179 members are malignant.  So 24 are false negatives and 179 are true positives.

In cluster 2, 333 members are benign and 33 are malignant.  So 33 are false positives.

Balance of sensitivity and specificity depends on what the data is.

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=grps)
```

## Section 7: Prediction

We will use the `predict()` function that will take our PCA model from before and new cancer cell data and project that data onto our PCA space.

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=wisc.df$diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], labels=c(1,2), col="white")
```


